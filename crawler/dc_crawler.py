import time
import requests
from bs4 import BeautifulSoup

HEADERS = {"User-Agent": "Mozilla/5.0"}
BASE_URL = "https://gall.dcinside.com"

def crawl_dcinside():
    session = requests.Session()
    session.headers.update(HEADERS)

    list_url = f"{BASE_URL}/mgallery/board/lists/?id=dfip&sort_type=N&exception_mode=recommend&search_head=10&page=1"
    resp = session.get(list_url)
    soup = BeautifulSoup(resp.text, "html.parser")

    posts = soup.select("tr.ub-content.us-post")
    print(f"ğŸ” ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")

    for post in posts:
        subject_tag = post.select_one("td.gall_subject")
        if subject_tag and "ê³µì§€" in subject_tag.text:
            continue

        link_tag = post.select_one("td.gall_tit a[href*='view']")
        if not link_tag:
            continue

        post_url = BASE_URL + link_tag["href"]
        print(f"\nğŸ”— ê²Œì‹œê¸€ URL: {post_url}")

        try:
            resp_post = session.get(post_url)
            post_soup = BeautifulSoup(resp_post.text, "html.parser")

            title = post_soup.select_one(".title_subject")
            title_text = title.get_text(strip=True) if title else "[ì œëª© ì—†ìŒ]"

            date = post_soup.select_one("span.gall_date")
            date_text = date.get_text(strip=True) if date else "[ë‚ ì§œ ì—†ìŒ]"

            content_div = post_soup.select_one("div.write_div")
            content_text = content_div.get_text("\n", strip=True) if content_div else "[ë³¸ë¬¸ ì—†ìŒ]"

            print("ğŸ“Œ ì œëª©:", title_text)
            print("ğŸ•’ ì‘ì„±ì¼:", date_text)
            print("ğŸ“ ë³¸ë¬¸ ì¼ë¶€:", content_text[:100], "...")

            time.sleep(1.5)

        except Exception as e:
            print("âŒ ì—ëŸ¬ ë°œìƒ:", e)

if __name__ == "__main__":
    crawl_dcinside()