import time
import requests
from bs4 import BeautifulSoup

HEADERS = {"User-Agent": "Mozilla/5.0"}
BASE_URL = "https://df.nexon.com"

def crawl_df():
    session = requests.Session()
    session.headers.update(HEADERS)

    list_url = f"{BASE_URL}/community/dnfboard/list?category=99"
    resp = session.get(list_url)
    soup = BeautifulSoup(resp.text, "html.parser")

    posts = soup.select("article.board_list > ul")
    print(f"ğŸ” ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")

    for post in posts:
        # ê³µì§€ê¸€ ì œì™¸
        if 'notice' in post.get("class", []):
            continue

        # ì œëª© ë° ë§í¬
        title_li = post.select_one("li.title")
        if not title_li:
            continue

        # ê²Œì‹œê¸€ ë§í¬
        link_tag = title_li.find_all("a")[-1]  # ë§ˆì§€ë§‰ aíƒœê·¸ê°€ ì‹¤ì œ ë§í¬ì„
        href = link_tag.get("href", "").strip()
        if not href.startswith("/community/dnfboard/article/"):
            continue
        post_url = BASE_URL + href
        print(f"\nğŸ”— ê²Œì‹œê¸€ URL: {post_url}")

        try:
            # ìƒì„¸ í˜ì´ì§€ ìš”ì²­
            resp_post = session.get(post_url)
            post_soup = BeautifulSoup(resp_post.text, "html.parser")

            # ì œëª©
            title_tag = post_soup.select_one("p.commu1st span")
            title_text = title_tag.get_text(separator="", strip=True) if title_tag else "[ì œëª© ì—†ìŒ]"
            title_text = " ".join(title_text.split())

            # ë‚ ì§œ
            date_tag = post_soup.select_one("li.date")
            date_text = date_tag.get_text(strip=True) if date_tag else "[ë‚ ì§œ ì—†ìŒ]"

            # ë³¸ë¬¸
            content_div = post_soup.select_one("div.bd_viewcont")
            content_text = content_div.get_text("\n", strip=True) if content_div else "[ë³¸ë¬¸ ì—†ìŒ]"

            print("ğŸ“Œ ì œëª©:", title_text)
            print("ğŸ•’ ì‘ì„±ì¼:", date_text)
            print("ğŸ“ ë³¸ë¬¸ ì¼ë¶€:", content_text[:100], "...")

            time.sleep(1.5)

        except Exception as e:
            print("âŒ ì—ëŸ¬ ë°œìƒ:", e)

if __name__ == "__main__":
    crawl_df()