"""
RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì›¹ ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°
"""
from typing import Dict, List, Optional
from langchain.docstore.document import Document
from google import genai
from google.genai.types import GenerateContentConfig, GoogleSearch, Tool
from .text_utils import TextProcessor


class WebSearcher:
    """ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, gemini_client: genai.Client):
        """
        Args:
            gemini_client: Gemini API í´ë¼ì´ì–¸íŠ¸
        """
        self.gemini_client = gemini_client
        self.text_processor = TextProcessor()
    
    def search_with_grounding(self, query: str, character_info: Optional[Dict]) -> List[Document]:
        """Gemini Search Groundingì„ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰"""
        enhanced_query = self.text_processor.enhance_query_with_character(query, character_info)
        
        # ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ (ë˜íŒŒ ì „ë¬¸ê°€ ì›¹ê²€ìƒ‰ ë²„ì „)
        system_instruction = """
ë‹¹ì‹ ì€ ë˜ì „ì•¤íŒŒì´í„° ì „ë¬¸ ì •ë³´ ì œê³µìì…ë‹ˆë‹¤.

[ğŸ“… ìµœì‹  ì •ë³´ ì œí•œ ì¡°ê±´]
- ë°˜ë“œì‹œ **2025ë…„ 1ì›” 9ì¼ ì´í›„ì˜ ì •ë³´ë§Œ ì‚¬ìš©**í•˜ì„¸ìš”.
- ê²€ìƒ‰ ì‹œ "2025ë…„", "4ì›”", "5ì›”" ë“±ì˜ **ëª…í™•í•œ ë‚ ì§œ í‚¤ì›Œë“œ**ê°€ í¬í•¨ëœ ì •ë³´ë§Œ ì±„íƒí•˜ì„¸ìš”.
- ë‚ ì§œê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ì •ë³´ëŠ” **ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”**.
- ì¤‘ë³µë˜ê±°ë‚˜ ì¶©ëŒí•˜ëŠ” ì •ë³´ëŠ” **ë‚ ì§œê°€ ê°€ì¥ ìµœì‹ ì¸ ì •ë³´ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œ**í•˜ì„¸ìš”.

[ğŸ” ê²€ìƒ‰ ìµœì í™” ê·œì¹™]
- ì˜¤ë˜ëœ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œë‚˜ ìš”ì•½ì€ ìƒëµí•˜ì„¸ìš”.
- ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ì„¤ëª…ì€ ì œê±°í•˜ê³ , **ëª…í™•í•œ ìˆ˜ì¹˜, ëª…ì¹­, ëª…ì„± ê¸°ì¤€ì´ í¬í•¨ëœ ì •ë³´ë§Œ ì„ íƒ**í•˜ì„¸ìš”.
- â€œìµœì‹  íŒ¨ì¹˜â€, â€œ2025 ì´ë²¤íŠ¸â€, â€œì‹ ê·œ ì½˜í…ì¸ â€ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•„í„°ë§í•˜ì„¸ìš”.

[ğŸ¯ ëª©í‘œ]
- **2025ë…„ ê¸°ì¤€ ìµœì‹  ë˜íŒŒ ì •ë³´ë§Œ ì œê³µ**
- ìºë¦­í„° ë§ì¶¤í˜• ìŠ¤í™ì—… ê°€ì´ë“œë¥¼ ê°„ê²°í•˜ê²Œ ì•ˆë‚´
- ì“¸ë°ì—†ëŠ” ìš”ì•½ ì—†ì´ **í•µì‹¬ ìˆ˜ì¹˜ì™€ ì¡°ê±´ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€**

[ğŸ“˜ ë‹µë³€ ê¸°ì¤€]
- **ê³µì‹ í™ˆí˜ì´ì§€ ë˜ëŠ” ëª…í™•í•œ ì¶œì²˜ê°€ ìˆëŠ” ì •ë³´**ë¥¼ ìµœìš°ì„  ì‚¬ìš©
- ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì¹´ë”ë¼ ì •ë³´ëŠ” ë°°ì œ
- **ê°„ê²°í•˜ê²Œ í•œ ë¬¸ë‹¨ ì´ë‚´**ë¡œ ë‹µë³€
- í•„ìš” ì‹œ ëª…í™•í•œ â€œì¶œì²˜ ì´ë¦„ ë˜ëŠ” ë‚ ì§œâ€ë¥¼ í•¨ê»˜ ëª…ì‹œ
"""
        # ìºë¦­í„° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        character_context_str = self.text_processor.build_character_context_for_search(character_info)
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        final_prompt = (
            f"{system_instruction}\n{character_context_str}\n"
            f"[ê²€ìƒ‰ ìš”ì²­]\n2025ë…„ ë˜ì „ì•¤íŒŒì´í„° \"{enhanced_query}\"ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ë‹¨ê³„ë³„ë¡œ ìˆœì„œí™”í•˜ì—¬ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
        )
        
        try:
            print(f"[DEBUG] Gemini ê²€ìƒ‰ ì‹¤í–‰: {enhanced_query}")
            
            # Google Search ë„êµ¬ ì„¤ì •
            google_search_tool = Tool(google_search=GoogleSearch())
            
            # Gemini API í˜¸ì¶œ
            response = self.gemini_client.models.generate_content(
                model="gemini-2.5-flash-preview-05-20",
                contents=final_prompt,
                config=GenerateContentConfig(
                    tools=[google_search_tool],
                    temperature=0.1,  # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
                    max_output_tokens=2000
                )
            )
            
            # ì‘ë‹µì—ì„œ ë¬¸ì„œ ì¶”ì¶œ
            docs = self._extract_documents_from_response(response)
            
            print(f"[DEBUG] Gemini ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ {len(docs)}ê°œ ìƒì„±")
            return docs
            
        except Exception as e:
            print(f"âŒ Gemini ê²€ìƒ‰ ê·¸ë¼ìš´ë”© ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_documents_from_response(self, response) -> List[Document]:
        """Gemini ì‘ë‹µì—ì„œ Document ê°ì²´ë“¤ì„ ì¶”ì¶œ"""
        docs = []
        
        if not response.candidates:
            return docs
        
        candidate = response.candidates[0]
        
        # ë©”ì¸ ì»¨í…ì¸  ì¶”ì¶œ
        if candidate.content and candidate.content.parts:
            main_content = "".join(
                part.text for part in candidate.content.parts 
                if hasattr(part, 'text') and part.text
            )
            if main_content:
                docs.append(Document(
                    page_content=main_content, 
                    metadata={"title": "Gemini ê²€ìƒ‰ ê²°ê³¼", "source": "gemini_search"}
                ))
        
        # Grounding ë©”íƒ€ë°ì´í„° ì²˜ë¦¬
        if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
            grounding = candidate.grounding_metadata
            
            # ê²€ìƒ‰ ì œì•ˆì‚¬í•­
            if hasattr(grounding, 'search_entry_point') and grounding.search_entry_point:
                docs.append(Document(
                    page_content="Google ê²€ìƒ‰ ì œì•ˆì‚¬í•­ ë° ê´€ë ¨ ë§í¬", 
                    metadata={"title": "ê²€ìƒ‰ ì œì•ˆ", "source": "search_suggestions"}
                ))
            
            # Grounding ì²­í¬ë“¤
            if hasattr(grounding, 'grounding_chunks') and grounding.grounding_chunks:
                for i, chunk in enumerate(grounding.grounding_chunks):
                    if hasattr(chunk, 'web') and chunk.web:
                        web_info = chunk.web
                        docs.append(Document(
                            page_content=f"ì¶œì²˜ {i+1}ì—ì„œ ì°¸ì¡°ëœ ì •ë³´",
                            metadata={
                                "title": getattr(web_info, 'title', f'ì›¹ ì¶œì²˜ {i+1}'), 
                                "url": getattr(web_info, 'uri', ''), 
                                "source": "grounding_source"
                            }
                        ))
            
            # ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ ë¡œê¹…
            if hasattr(grounding, 'web_search_queries') and grounding.web_search_queries:
                print(f"[DEBUG] ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬: {grounding.web_search_queries}")
        
        return docs
