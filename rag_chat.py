import os
import requests
import json
import sys
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.schema import Document
from openai import OpenAI

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not GEMINI_API_KEY:
    print("ì˜¤ë¥˜: GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

if not PERPLEXITY_API_KEY:
    print("ê²½ê³ : PERPLEXITY_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ë²¡í„° DB ê²½ë¡œ
CHROMA_DIR = "vector_db/chroma"

# 1. ë²¡í„° DB ë¡œë“œ
embedding_model = GoogleGenerativeAIEmbeddings(
        google_api_key=GEMINI_API_KEY,
        model="models/text-embedding-004"
    )
vectordb = Chroma(
    persist_directory=CHROMA_DIR,
    embedding_function=embedding_model
)

# 2. LLM ì„¤ì •
llm = ChatGoogleGenerativeAI(
    google_api_key=GEMINI_API_KEY,
    model="models/gemini-2.5-flash-preview-05-20", temperature=0)

# 3. ë‚´ë¶€ RAG ê²€ìƒ‰ê¸° ì„¤ì •
internal_retriever = vectordb.as_retriever(
    search_type="mmr",
    search_kwargs={
        "k": 6,
        "fetch_k": 12,
        "lambda_mult": 0.7
    }
)

# 4. Perplexity APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰ í•¨ìˆ˜
def perplexity_web_search(query, max_results=3):
    api_key = PERPLEXITY_API_KEY
    
    if not api_key:
        return []
    
    try:
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.perplexity.ai"
        )
        
        messages = [
            {
                "role": "system",
                "content": (
                    "You are a helpful assistant that provides information about "
                    "Dungeon & Fighter (DNF) game. Focus exclusively on providing the most "
                    "recent and accurate information about character progression, equipment, "
                    "and optimization guides. Extract only the key facts and essential details "
                    "from your search results. Prioritize information from 2025 sources. "
                    "Be concise and direct, omitting any unnecessary context or introduction. "
                    "Format your response as clear, actionable points whenever possible."
                )
            },
            {"role": "user", "content": f"2025 ìµœì‹  ë˜ì „ì•¤íŒŒì´í„° {query} ìŠ¤í™ì—… ê°€ì´ë“œ"}
        ]
        
        response = client.chat.completions.create(
            model="sonar",
            messages=messages,
            max_tokens=1000,
            temperature=0
        )
        
        docs = []
        
        content = response.choices[0].message.content
        docs.append(Document(
            page_content=content,
            metadata={"title": "Perplexity ê²€ìƒ‰ ê²°ê³¼", "url": "", "source": "web_search"}
        ))
        
        citations = []
        if hasattr(response, "citations"):
            citations = response.citations
        elif hasattr(response.choices[0].message, "context") and hasattr(response.choices[0].message.context, "citations"):
            citations = response.choices[0].message.context.citations
            
        if citations:
            for citation in citations[:max_results]:
                if isinstance(citation, dict):
                    title = citation.get("title", "ì œëª© ì—†ìŒ")
                    url = citation.get("url", "ë§í¬ ì—†ìŒ")
                    text = citation.get("text", "")
                else:
                    title = str(citation)
                    url = "ë§í¬ ì—†ìŒ"
                    text = ""
                docs.append(Document(
                    page_content=f"{title}\n{text}",
                    metadata={"title": title, "url": url, "source": "web_search"}
                ))
                
        return docs
            
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¡°ìš©íˆ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []

# 5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í•¨ìˆ˜
def hybrid_search(query):
    """ë‚´ë¶€ RAGì™€ ì›¹ ê²€ìƒ‰ì„ í•­ìƒ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
    # ë‚´ë¶€ RAGì—ì„œ ì •ë³´ ê²€ìƒ‰
    internal_docs = internal_retriever.get_relevant_documents(query)
    
    # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
    web_docs = perplexity_web_search(query)
    
    # ë¬¸ë§¥ êµ¬ì„±
    internal_context = "\n\n".join([doc.page_content for doc in internal_docs])
    web_context = "\n\n".join([doc.page_content for doc in web_docs]) if web_docs else ""
    
    return {
        "all_docs": internal_docs + web_docs,
        "internal_docs": internal_docs,
        "web_docs": web_docs,
        "internal_context": internal_context,
        "web_context": web_context,
        "used_web_search": len(web_docs) > 0
    }

# 6. í•˜ì´ë¸Œë¦¬ë“œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
hybrid_prompt = PromptTemplate(
    input_variables=["internal_context", "web_context", "question"],
    template="""
ë‹¹ì‹ ì€ ë˜ì „ì•¤íŒŒì´í„° ì „ë¬¸ ìŠ¤í™ì—… ê°€ì´ë“œ ì±—ë´‡ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë‘ ê°€ì§€ ì •ë³´ ì†ŒìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

1. ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ (ê¸°ì¡´ ê°€ì´ë“œ ë° ì»¤ë®¤ë‹ˆí‹° ì •ë³´):
{internal_context}

2. ì›¹ ê²€ìƒ‰ ì •ë³´ (ìµœì‹  ì—…ë°ì´íŠ¸ ë° ì¶”ê°€ ì •ë³´):
{web_context}

ì •ë³´ ê°€ì¤‘ì¹˜ ì§€ì¹¨:
- ì›¹ ê²€ìƒ‰ ì •ë³´ì— 50%, ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ì— 50%ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‘ê³  ì‘ë‹µì„ êµ¬ì„±í•˜ì„¸ìš”.
- ë‘ ì •ë³´ ì†ŒìŠ¤ê°€ ìƒì¶©í•  ê²½ìš° ìµœì‹  ì •ë³´ë¥¼ ìš°ì„ í•˜ì„¸ìš”.
- ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì—†ëŠ” ê²½ìš°ì—ë„ ìµœì„ ì„ ë‹¤í•´ ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ ì§€ì¹¨:
- 2025ë…„ ì´ì „ì˜ ë°ì´í„°ëŠ” ì˜ë¯¸ê°€ ì—†ìœ¼ë‹ˆ ì°¸ì¡°í•˜ì§€ ë§ˆì„¸ìš”.
- ë¶ˆí•„ìš”í•œ ì„œë¡ ì´ë‚˜ ë°°ê²½ ì„¤ëª… ì—†ì´ í•µì‹¬ ì •ë³´ë§Œ ì „ë‹¬í•˜ì„¸ìš”.
- ìŠ¤í™ì—… ìˆœì„œë‚˜ ìš°ì„ ìˆœìœ„ë¥¼ ì œì‹œí•  ë•ŒëŠ” ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ ì•ˆë‚´í•˜ì„¸ìš”.
- 1,2,3 ì´ëŸ°ì‹ìœ¼ë¡œ ìˆœì„œë¥¼ í†µí•´ ìš°ì„ ìˆœìœ„ë¥¼ ì œì‹œí•˜ì„¸ìš”.
- ì‹ ë¢°ì„±ì´ ë†’ì€ ì •ë³´ëŠ” ë” ìƒì„¸í•˜ê²Œ ì œê³µí•˜ì„¸ìš”.
- ì‹ ë¢°ì„±ì´ ë–¨ì–´ì§€ëŠ” ì •ë³´ëŠ” ëª…ì¹­ì„ ìƒëµí•˜ëŠ” ì‹ìœ¼ë¡œ ì¶”ìƒí™”í•˜ì—¬ ì§§ê²Œ ì œê³µí•˜ì„¸ìš”.
- ìºë¦­í„° ì§ì—…ì„ ë§í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—” ê³µí†µì ì¸ ë‚´ìš©ë§Œ ì„¤ëª…í•˜ì„¸ìš”.
- ìƒí™©ì— ë”°ë¼ ë˜íŒŒ API ì‚¬ì´íŠ¸ë¥¼ ì ì ˆíˆ ì¶”ì²œí•´ì£¼ëŠ” ë°©ì‹ì„ ì±„ìš©í•˜ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€:
"""
)

# 7. í•˜ì´ë¸Œë¦¬ë“œ ì²´ì¸ ì„¤ì •
hybrid_chain = LLMChain(llm=llm, prompt=hybrid_prompt)

# 8. í†µí•© ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_answer(query):
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
    search_results = hybrid_search(query)
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ì‚¬ìš©
    response = hybrid_chain.run(
        internal_context=search_results["internal_context"],
        web_context=search_results["web_context"],
        question=query
    )
    
    return {
        "result": response,
        "source_documents": search_results["all_docs"],
        "used_web_search": search_results["used_web_search"],
        "internal_docs": search_results["internal_docs"], 
        "web_docs": search_results["web_docs"]
    }

# 9. ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì§ˆë¬¸ì„ ë°›ì•„ í•œ ë²ˆë§Œ ë‹µë³€í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
def main():
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì§ˆë¬¸ì„ ë°›ìŒ
    if len(sys.argv) > 1:
        # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì „ë‹¬ëœ ì§ˆë¬¸ ì‚¬ìš©
        query = " ".join(sys.argv[1:])
    else:
        # ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ì—†ìœ¼ë©´ í‘œì¤€ ì…ë ¥ì—ì„œ í•œ ì¤„ ì½ê¸°
        print("ë˜íŒŒ ìŠ¤í™ì—… ê°€ì´ë“œ ì±—ë´‡\n")
        query = input("ì§ˆë¬¸: ")
    
    if not query or query.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
        print("ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‘ë‹µ ìƒì„±
    result = get_answer(query)
    
    # ì›¹ ê²€ìƒ‰ ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ ì¶œë ¥
    if result["used_web_search"]:
        print("\nâœ… ì›¹ ê²€ìƒ‰ ë° ë‚´ë¶€ DB ì‚¬ìš©")
    else:
        print("\nâš ï¸ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ - ë‚´ë¶€ DBë§Œ ì‚¬ìš©")
    
    # ê²°ê³¼ ì¶œë ¥
    print("\në‹µë³€:")
    print(result["result"])
    
    # ì¶œì²˜ ì •ë³´ ì¶œë ¥
    print("\nì¶œì²˜:")
    
    # ì¶œì²˜ ë¬¸ì„œ ì¶œë ¥ (ì›¹ ê²€ìƒ‰ ê²°ê³¼ ë¨¼ì €, ê·¸ ë‹¤ìŒ ë‚´ë¶€ DB)
    for doc in result["web_docs"]:
        print(f"ğŸŒ {doc.metadata.get('title', 'ì œëª© ì—†ìŒ')} ({doc.metadata.get('url', 'ë§í¬ ì—†ìŒ')})")
        
    for doc in result["internal_docs"][:3]:  # ë‚´ë¶€ DBëŠ” ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
        print(f"ğŸ—„ï¸ {doc.metadata.get('title', 'ì œëª© ì—†ìŒ')} ({doc.metadata.get('url', 'ë§í¬ ì—†ìŒ')})")

if __name__ == "__main__":
    main()
