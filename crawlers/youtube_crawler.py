# youtube_crawler.py ìˆ˜ì •ì•ˆ
from __future__ import annotations
from datetime import datetime, timezone
import json, time, sys, urllib.parse
from pathlib import Path

import yt_dlp                          # pip install yt-dlp
from youtube_transcript_api import (
    YouTubeTranscriptApi,
    TranscriptsDisabled,
    NoTranscriptFound,
    CouldNotRetrieveTranscript
)

from utils import build_item           # priority_scoreÂ·class_name ìë™ ë¶€ì—¬

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAVE_PATH = Path("data/raw/youtube_raw.json")

# yt-dlp ê¸°ë³¸ ì˜µì…˜
YDL_FLAT_OPTS = {
    "quiet": True,
    "skip_download": True,
    "extract_flat": True,      # ì˜ìƒ IDÂ·ì œëª©ë§Œ
    "nocheckcertificate": True,
}
YDL_META_OPTS = {
    "quiet": True,
    "skip_download": True,
    "nocheckcertificate": True,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_youtube_videos(query, max_results=20):
    """
    YouTube ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì˜ìƒ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
    Returns:
        list[str]: ì˜ìƒ ID ëª©ë¡
    """
    # ê²€ìƒ‰ URL ì¸ì½”ë”©
    search_url = f"ytsearch{max_results}:{query}"
    
    try:
        with yt_dlp.YoutubeDL(YDL_FLAT_OPTS) as ydl:
            info = ydl.extract_info(search_url, download=False)
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì˜ìƒ ID ì¶”ì¶œ
            entries = info.get("entries", [])
            video_ids = []

            for entry in entries:
                # ì˜ìƒ IDê°€ ìˆì„ ê²½ìš° ì¶”ì¶œ
                vid = entry.get("id") or ""
                if len(vid) == 11:  # ìœ íŠœë¸Œ video_idëŠ” í•­ìƒ 11ìë¦¬
                    video_ids.append(vid)

            return video_ids
    except Exception as e:
        return []

def list_channel_video_ids(channel_url: str, limit: int) -> list[str]:
    """
    yt-dlp ë¡œ ì±„ë„ â†’ ì˜ìƒ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ limit ê°œ)
    """
    try:
        with yt_dlp.YoutubeDL(YDL_FLAT_OPTS) as ydl:
            info = ydl.extract_info(channel_url, download=False)
            
            # ì±„ë„ì´ë©´ entries ì•ˆì— ë‹¤ì‹œ video entriesê°€ ìˆëŠ” ê²½ìš°
            entries = info.get("entries", [])
            video_ids = []

            for entry in entries[:limit]:
                # ì˜ìƒ IDê°€ ìˆì„ ê²½ìš° ì¶”ì¶œ
                vid = entry.get("id") or ""
                if len(vid) == 11:  # ìœ íŠœë¸Œ video_idëŠ” í•­ìƒ 11ìë¦¬
                    video_ids.append(vid)

            return video_ids
    except Exception as e:
        return []

def fetch_video_meta(video_id: str) -> dict:
    """yt-dlp ë¡œ ì˜ìƒ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
    url = f"https://www.youtube.com/watch?v={video_id}"
    try:
        with yt_dlp.YoutubeDL(YDL_META_OPTS) as ydl:
            info = ydl.extract_info(url, download=False)
        # upload_date: 'YYYYMMDD'
        date_obj = datetime.strptime(info["upload_date"], "%Y%m%d").replace(tzinfo=timezone.utc)
        return {
            "title": info["title"],
            "date": date_obj,
            "views": info.get("view_count", 0) or 0,
            "likes": info.get("like_count", 0) or 0,
        }
    except Exception as e:
        return {
            "title": f"YOUTUBE_{video_id}",
            "date": datetime.now(timezone.utc),
            "views": 0,
            "likes": 0,
        }

def fetch_caption_text(video_id: str) -> str:
    """ìë§‰ ê°€ì ¸ì˜¤ê¸°"""
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=("ko", "en"))
        return " ".join(seg["text"].strip() for seg in transcript if seg["text"].strip())
    except (TranscriptsDisabled, NoTranscriptFound, CouldNotRetrieveTranscript) as e:
        return ""
    except Exception as e:
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def crawl_youtube_search(search_query: str, max_videos: int, visited_urls=None) -> list[dict]:
    """
    YouTube ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§
    
    Args:
        search_query: ê²€ìƒ‰ ì¿¼ë¦¬
        max_videos: ê°€ì ¸ì˜¬ ìµœëŒ€ ì˜ìƒ ìˆ˜
        visited_urls: ì´ë¯¸ ë°©ë¬¸í•œ URL ì§‘í•© (ì¦ë¶„ í¬ë¡¤ë§ ì§€ì›)
    """
    # ì¦ë¶„ í¬ë¡¤ë§ì„ ìœ„í•œ ë°©ë¬¸ URL ê´€ë¦¬
    if visited_urls is None:
        visited_urls = set()
    
    # ê²€ìƒ‰ ê²°ê³¼ ì˜ìƒ ID ê°€ì ¸ì˜¤ê¸°
    video_ids = search_youtube_videos(search_query, max_videos)
    
    return process_video_ids(video_ids, visited_urls)

def crawl_youtube_channel(channel_url: str, max_videos: int, visited_urls=None) -> list[dict]:
    """
    YouTube ì±„ë„ì˜ ì˜ìƒ í¬ë¡¤ë§
    
    Args:
        channel_url: YouTube ì±„ë„ URL
        max_videos: ê°€ì ¸ì˜¬ ìµœëŒ€ ì˜ìƒ ìˆ˜
        visited_urls: ì´ë¯¸ ë°©ë¬¸í•œ URL ì§‘í•© (ì¦ë¶„ í¬ë¡¤ë§ ì§€ì›)
    """
    # ì¦ë¶„ í¬ë¡¤ë§ì„ ìœ„í•œ ë°©ë¬¸ URL ê´€ë¦¬
    if visited_urls is None:
        visited_urls = set()
    
    # ì˜ìƒ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    video_ids = list_channel_video_ids(channel_url, max_videos)
    
    return process_video_ids(video_ids, visited_urls)

def process_video_ids(video_ids, visited_urls):
    """
    ì˜ìƒ ID ëª©ë¡ì„ ì²˜ë¦¬í•˜ì—¬ ìë§‰ì´ ìˆëŠ” ì˜ìƒë§Œ ì €ì¥
    
    Args:
        video_ids: ì˜ìƒ ID ëª©ë¡
        visited_urls: ë°©ë¬¸í•œ URL ì§‘í•©
    """
    results = []
    start_time = time.time()

    for vid in video_ids:
        url = f"https://www.youtube.com/watch?v={vid}"
        
        # ì¦ë¶„ í¬ë¡¤ë§: ì´ë¯¸ ë°©ë¬¸í•œ URLì´ë©´ ê±´ë„ˆëœ€
        if url in visited_urls:
            continue
            
        # ë°©ë¬¸ ê¸°ë¡ì— ì¶”ê°€
        visited_urls.add(url)

        # 1) ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        meta = fetch_video_meta(vid)

        # 2) ìë§‰ ê°€ì ¸ì˜¤ê¸°
        caption = fetch_caption_text(vid)
        if not caption:
            continue    # ìë§‰ ì—†ëŠ” ì˜ìƒì€ ë‰´ë¹„ ê°€ì´ë“œë¡œ ì“°ê¸° ì–´ë µë‹¤ íŒë‹¨

        # 3) utils.build_item â†’ priority_score / class_name ìë™ ë¶€ì—¬
        item = build_item(
            source="youtube",
            url=url,
            title=meta["title"],
            body=caption,
            date=meta["date"],
            views=meta["views"],
            likes=meta["likes"],
        )
        results.append(item)

        # API/ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
        time.sleep(2.0)

    # ê²°ê³¼ ìš”ì•½
    elapsed_time = time.time() - start_time

    # ğŸ“‚ ê²°ê³¼ ì €ì¥
    save_dir = Path(SAVE_PATH).parent
    save_dir.mkdir(parents=True, exist_ok=True)
    
    with open(SAVE_PATH, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    return results

# ì´ì „ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜
def crawl_youtube(source: str, max_videos: int, visited_urls=None) -> list[dict]:
    """
    YouTube í¬ë¡¤ë§ (ì±„ë„ URL ë˜ëŠ” ê²€ìƒ‰ì–´)
    
    Args:
        source: ì±„ë„ URL ë˜ëŠ” ê²€ìƒ‰ì–´
        max_videos: ê°€ì ¸ì˜¬ ìµœëŒ€ ì˜ìƒ ìˆ˜
        visited_urls: ì´ë¯¸ ë°©ë¬¸í•œ URL ì§‘í•© (ì¦ë¶„ í¬ë¡¤ë§ ì§€ì›)
    """
    # sourceê°€ URLì¸ì§€ ê²€ìƒ‰ì–´ì¸ì§€ íŒë‹¨
    if source.startswith(("http://", "https://", "www.")):
        # URL - ì±„ë„ í¬ë¡¤ë§
        return crawl_youtube_channel(source, max_videos, visited_urls)
    else:
        # ê²€ìƒ‰ì–´ - ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§
        return crawl_youtube_search(source, max_videos, visited_urls)

# ì§ì ‘ ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        query_or_channel = sys.argv[1]
    else:
        # ê¸°ë³¸ ê²€ìƒ‰ì–´
        query_or_channel = "ë˜íŒŒ ê°€ì´ë“œ"
        
    # ê°€ì ¸ì˜¬ ì˜ìƒ ìˆ˜
    max_videos = 10
    if len(sys.argv) > 2:
        try:
            max_videos = int(sys.argv[2])
        except ValueError:
            pass
    
    print(f"YouTube í¬ë¡¤ë§ ì‹œì‘: {query_or_channel} (ìµœëŒ€ {max_videos}ê°œ)")
    
    # ê²€ìƒ‰ì–´ ë˜ëŠ” ì±„ë„ URLì— ë”°ë¼ ë‹¤ë¥¸ í•¨ìˆ˜ í˜¸ì¶œ
    results = crawl_youtube(query_or_channel, max_videos)
    print(f"í¬ë¡¤ë§ ì™„ë£Œ: {len(results)}ê°œ ì˜ìƒ")
