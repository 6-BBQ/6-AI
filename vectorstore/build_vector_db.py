from __future__ import annotations

import json
import logging
import os
from pathlib import Path
from typing import Dict, List
from dotenv import load_dotenv

from langchain.docstore.document import Document
from langchain_community.vectorstores import Chroma

from langchain_openai import OpenAIEmbeddings

load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ ì„¤ì •
PROCESSED_PATH = Path("data/processed_docs.jsonl")
CHROMA_DIR = "vector_db/chroma"        # persist ë””ë ‰í„°ë¦¬
BATCH_SIZE = 200                       # ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬ì™€ ë§ì¶°ì„œ ì¦ê°€
MODEL_NAME = "text-embedding-3-large"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
log = logging.getLogger("build_vector_db")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ ì„ë² ë”© & DB ì´ˆê¸°í™”
log.info("ğŸš€ ì„ë² ë”© ê¸°ë°˜ ë²¡í„° DB êµ¬ì¶• ì‹œì‘ (í•œêµ­ì–´ ì„±ëŠ¥ ìµœì í™”)")

# ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™”
embedding_fn = OpenAIEmbeddings(
    model=MODEL_NAME,
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# ë¨¼ì € ê¸°ì¡´ í´ë” ì œê±°
if Path(CHROMA_DIR).exists():
    log.info("ğŸ§¹ ê¸°ì¡´ Chroma í´ë” ì‚­ì œ í›„ ì¬ìƒì„±")
    import shutil
    shutil.rmtree(CHROMA_DIR)

# ì´í›„ ìƒˆë¡œ ìƒì„±
vectordb = Chroma(
    persist_directory=CHROMA_DIR,
    embedding_function=embedding_fn,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ JSONL â†’ Document ë¦¬ìŠ¤íŠ¸
def load_docs(path: Path) -> List[Document]:
    docs: List[Document] = []
    with path.open(encoding="utf-8") as f:
        for line in f:
            raw: Dict = json.loads(line)
            docs.append(
                Document(
                    page_content=raw["content"],
                    metadata={
                        **raw["metadata"],
                        "doc_id": raw["id"],
                    },
                )
            )
    return docs


all_docs = load_docs(PROCESSED_PATH)
total = len(all_docs)
log.info("ğŸ“„ %dê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ â†’ OpenAI ì„ë² ë”©/DB ì €ì¥", total)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£ ë°°ì¹˜ ì„ë² ë”© & ì—…ë¡œë“œ
log.info("ğŸ”„ ë°°ì¹˜ ì„ë² ë”© ë° ì—…ë¡œë“œ ì‹œì‘")

for i in range(0, total, BATCH_SIZE):
    batch = all_docs[i : i + BATCH_SIZE]
    
    log.info(f"ğŸ“¦ ë°°ì¹˜ {i//BATCH_SIZE + 1}: {len(batch)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
    
    try:
        vectordb.add_documents(batch)
        log.info("âœ… ë°°ì¹˜ %d ì™„ë£Œ: %d / %d ì—…ë¡œë“œ", i//BATCH_SIZE + 1, min(i + BATCH_SIZE, total), total)
        
        # ë°°ì¹˜ ê°„ ê°„ë‹¨í•œ ì§€ì—°
        if i + BATCH_SIZE < total:
            import time
            time.sleep(0.5)
            
    except Exception as e:
        log.error(f"âŒ ë°°ì¹˜ {i//BATCH_SIZE + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        log.info("â¸ï¸ 10ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
        import time
        time.sleep(10.0)
        
        try:
            vectordb.add_documents(batch)
            log.info("âœ… ì¬ì‹œë„ ì„±ê³µ: ë°°ì¹˜ %d ì™„ë£Œ", i//BATCH_SIZE + 1)
        except Exception as e2:
            log.error(f"âŒ ì¬ì‹œë„ë„ ì‹¤íŒ¨: {e2}")
            continue

# Vector DB ì €ì¥
vectordb.persist()
log.info("ğŸ‰ ì„ë² ë”© ê¸°ë°˜ Vector DB ì €ì¥ ì™„ë£Œ â†’ %s", CHROMA_DIR)
log.info("ğŸ“Š ëª¨ë¸: %s", MODEL_NAME)
log.info("ğŸ“ˆ ì´ ë¬¸ì„œ ìˆ˜: %dê°œ", total)
